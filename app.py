"""
Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ Ø§Ù„Ø¢Ù„ÙŠ Ù„Ù…Ø°ÙƒØ±Ø§Øª Ø§Ù„ØªØ®Ø±Ø¬ - Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±
Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 1.0
Ø§Ù„ØªØ§Ø±ÙŠØ®: 2024
"""

from flask import Flask, request, jsonify
import pandas as pd
import numpy as np
from scipy import stats
import statsmodels.api as sm
from datetime import datetime
import requests
from io import BytesIO
import re
import traceback

app = Flask(__name__)

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†
app.config['MAX_CONTENT_LENGTH'] = 10 * 1024 * 1024  # 10MB max


class FileHandler:
    """Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…Ù„ÙØ§Øª - ØªØ­Ù…ÙŠÙ„ Ù…Ù† Google Drive"""
    
    def load_file(self, file_source):
        """ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ù…Ù† Google Drive Ø£Ùˆ Ø£ÙŠ Ù…ØµØ¯Ø±"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø±Ø§Ø¨Ø· Google Drive
            if 'drive.google.com' in file_source:
                file_source = self._convert_gdrive_url(file_source)
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
            response = requests.get(file_source, timeout=30)
            response.raise_for_status()
            file_content = BytesIO(response.content)
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
            if '.csv' in file_source.lower():
                df = pd.read_csv(file_content, encoding='utf-8-sig')
            else:
                df = pd.read_excel(file_content)
            
            return df
            
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {str(e)}")
            return None
    
    def _convert_gdrive_url(self, url):
        """ØªØ­ÙˆÙŠÙ„ Ø±Ø§Ø¨Ø· Google Drive Ù„Ù„ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±"""
        file_id = None
        
        # Ø§Ù„Ù†Ù…Ø· 1: /file/d/FILE_ID/
        match = re.search(r'/file/d/([a-zA-Z0-9_-]+)', url)
        if match:
            file_id = match.group(1)
        
        # Ø§Ù„Ù†Ù…Ø· 2: id=FILE_ID
        if not file_id:
            match = re.search(r'id=([a-zA-Z0-9_-]+)', url)
            if match:
                file_id = match.group(1)
        
        if file_id:
            return f"https://drive.google.com/uc?export=download&id={file_id}"
        
        return url


class DescriptiveAnalyzer:
    """Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØµÙÙŠ"""
    
    def __init__(self, dataframe):
        self.df = dataframe
    
    def run_analysis(self):
        """ØªØ­Ù„ÙŠÙ„ ÙˆØµÙÙŠ ÙƒØ§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª"""
        results = {
            "Ù…ØªØºÙŠØ±Ø§Øª_Ø±Ù‚Ù…ÙŠØ©": [],
            "Ù…ØªØºÙŠØ±Ø§Øª_ÙØ¦ÙˆÙŠØ©": []
        }
        
        for column in self.df.columns:
            try:
                if pd.api.types.is_numeric_dtype(self.df[column]):
                    # Ù…ØªØºÙŠØ± Ø±Ù‚Ù…ÙŠ
                    data = self.df[column].dropna()
                    if len(data) > 0:
                        results["Ù…ØªØºÙŠØ±Ø§Øª_Ø±Ù‚Ù…ÙŠØ©"].append({
                            "Ø§Ù„Ù…ØªØºÙŠØ±": column,
                            "Ø§Ù„Ø¹Ø¯Ø¯": int(len(data)),
                            "Ø§Ù„Ù…ØªÙˆØ³Ø·": round(float(data.mean()), 2),
                            "Ø§Ù„ÙˆØ³ÙŠØ·": round(float(data.median()), 2),
                            "Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù_Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ": round(float(data.std()), 2),
                            "Ø£ØµØºØ±_Ù‚ÙŠÙ…Ø©": round(float(data.min()), 2),
                            "Ø£ÙƒØ¨Ø±_Ù‚ÙŠÙ…Ø©": round(float(data.max()), 2)
                        })
                else:
                    # Ù…ØªØºÙŠØ± ÙØ¦ÙˆÙŠ
                    data = self.df[column].dropna()
                    if len(data) > 0:
                        counts = data.value_counts()
                        percentages = (counts / len(data) * 100).round(1)
                        
                        categories = []
                        for cat in counts.index[:5]:  # Ø£ÙˆÙ„ 5 ÙØ¦Ø§Øª
                            categories.append({
                                "Ø§Ù„ÙØ¦Ø©": str(cat),
                                "Ø§Ù„ØªÙƒØ±Ø§Ø±": int(counts[cat]),
                                "Ø§Ù„Ù†Ø³Ø¨Ø©": float(percentages[cat])
                            })
                        
                        results["Ù…ØªØºÙŠØ±Ø§Øª_ÙØ¦ÙˆÙŠØ©"].append({
                            "Ø§Ù„Ù…ØªØºÙŠØ±": column,
                            "Ø¹Ø¯Ø¯_Ø§Ù„ÙØ¦Ø§Øª": int(len(counts)),
                            "Ø§Ù„ØªÙˆØ²ÙŠØ¹": categories
                        })
            except:
                continue
        
        return results


class InferentialAnalyzer:
    """Ù…Ø­Ø±Ùƒ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ÙŠØ©"""
    
    def __init__(self, dataframe):
        self.df = dataframe
    
    def ttest(self, group_var, value_var):
        """Ø§Ø®ØªØ¨Ø§Ø± T Ù„Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ù„Ø©"""
        try:
            clean_df = self.df[[group_var, value_var]].dropna()
            groups = clean_df[group_var].unique()
            
            if len(groups) != 2:
                return {"error": f"ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ {group_var} Ø¹Ù„Ù‰ ÙØ¦ØªÙŠÙ† ÙÙ‚Ø·. Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {len(groups)}"}
            
            group1 = clean_df[clean_df[group_var] == groups[0]][value_var]
            group2 = clean_df[clean_df[group_var] == groups[1]][value_var]
            
            t_stat, p_value = stats.ttest_ind(group1, group2)
            
            # Ø­Ø¬Ù… Ø§Ù„Ø£Ø«Ø± (Cohen's d)
            pooled_std = np.sqrt(((len(group1)-1)*group1.std()**2 + (len(group2)-1)*group2.std()**2) / (len(group1)+len(group2)-2))
            cohens_d = (group1.mean() - group2.mean()) / pooled_std if pooled_std != 0 else 0
            
            return {
                "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©_1": {
                    "Ø§Ù„Ø§Ø³Ù…": str(groups[0]),
                    "Ø§Ù„Ø¹Ø¯Ø¯": int(len(group1)),
                    "Ø§Ù„Ù…ØªÙˆØ³Ø·": round(float(group1.mean()), 2),
                    "Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù": round(float(group1.std()), 2)
                },
                "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©_2": {
                    "Ø§Ù„Ø§Ø³Ù…": str(groups[1]),
                    "Ø§Ù„Ø¹Ø¯Ø¯": int(len(group2)),
                    "Ø§Ù„Ù…ØªÙˆØ³Ø·": round(float(group2.mean()), 2),
                    "Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù": round(float(group2.std()), 2)
                },
                "t": round(float(t_stat), 3),
                "p": round(float(p_value), 4),
                "cohens_d": round(float(cohens_d), 3),
                "Ø¯Ø§Ù„": p_value < 0.05,
                "ØªÙØ³ÙŠØ±": self._interpret_ttest(p_value, cohens_d)
            }
        except Exception as e:
            return {"error": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± T: {str(e)}"}
    
    def _interpret_ttest(self, p, d):
        """ØªÙØ³ÙŠØ± Ù†ØªØ§Ø¦Ø¬ Ø§Ø®ØªØ¨Ø§Ø± T"""
        result = []
        
        if p < 0.001:
            result.append("ÙŠÙˆØ¬Ø¯ ÙØ±Ù‚ Ø¯Ø§Ù„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Ù‹ Ø¹Ù†Ø¯ Ù…Ø³ØªÙˆÙ‰ 0.001 â­â­â­")
        elif p < 0.01:
            result.append("ÙŠÙˆØ¬Ø¯ ÙØ±Ù‚ Ø¯Ø§Ù„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Ù‹ Ø¹Ù†Ø¯ Ù…Ø³ØªÙˆÙ‰ 0.01 â­â­")
        elif p < 0.05:
            result.append("ÙŠÙˆØ¬Ø¯ ÙØ±Ù‚ Ø¯Ø§Ù„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Ù‹ Ø¹Ù†Ø¯ Ù…Ø³ØªÙˆÙ‰ 0.05 â­")
        else:
            result.append("Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙØ±Ù‚ Ø¯Ø§Ù„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Ù‹ âŒ")
        
        abs_d = abs(d)
        if abs_d < 0.2:
            result.append("Ø­Ø¬Ù… Ø§Ù„Ø£Ø«Ø±: Ø¶Ø¹ÙŠÙ Ø¬Ø¯Ø§Ù‹")
        elif abs_d < 0.5:
            result.append("Ø­Ø¬Ù… Ø§Ù„Ø£Ø«Ø±: ØµØºÙŠØ±")
        elif abs_d < 0.8:
            result.append("Ø­Ø¬Ù… Ø§Ù„Ø£Ø«Ø±: Ù…ØªÙˆØ³Ø·")
        else:
            result.append("Ø­Ø¬Ù… Ø§Ù„Ø£Ø«Ø±: ÙƒØ¨ÙŠØ±")
        
        return " | ".join(result)
    
    def anova(self, dependent, independent):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø§Ù„Ø£Ø­Ø§Ø¯ÙŠ (One-Way ANOVA)"""
        try:
            clean_df = self.df[[dependent, independent]].dropna()
            groups = [group[dependent].values for name, group in clean_df.groupby(independent)]
            group_names = clean_df[independent].unique()
            
            f_stat, p_value = stats.f_oneway(*groups)
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª
            group_stats = []
            for name in group_names:
                g_data = clean_df[clean_df[independent] == name][dependent]
                group_stats.append({
                    "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©": str(name),
                    "Ø§Ù„Ø¹Ø¯Ø¯": int(len(g_data)),
                    "Ø§Ù„Ù…ØªÙˆØ³Ø·": round(float(g_data.mean()), 2),
                    "Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù": round(float(g_data.std()), 2)
                })
            
            return {
                "Ø¹Ø¯Ø¯_Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª": len(groups),
                "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª": group_stats,
                "F": round(float(f_stat), 3),
                "p": round(float(p_value), 4),
                "Ø¯Ø§Ù„": p_value < 0.05,
                "ØªÙØ³ÙŠØ±": "ØªÙˆØ¬Ø¯ ÙØ±ÙˆÙ‚ Ø¯Ø§Ù„Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ§Ù‹ âœ…" if p_value < 0.05 else "Ù„Ø§ ØªÙˆØ¬Ø¯ ÙØ±ÙˆÙ‚ Ø¯Ø§Ù„Ø© âŒ"
            }
        except Exception as e:
            return {"error": f"Ø®Ø·Ø£ ÙÙŠ ANOVA: {str(e)}"}
    
    def correlation(self, variables):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· - Ø¨ÙŠØ±Ø³ÙˆÙ†ØŒ Ø³Ø¨ÙŠØ±Ù…Ø§Ù†ØŒ ÙƒÙŠÙ†Ø¯Ø§Ù„"""
        try:
            clean_df = self.df[variables].dropna()
            
            results = []
            for i in range(len(variables)):
                for j in range(i+1, len(variables)):
                    var1, var2 = variables[i], variables[j]
                    
                    # Ø¨ÙŠØ±Ø³ÙˆÙ† (Pearson) - Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø®Ø·ÙŠ
                    r_pearson, p_pearson = stats.pearsonr(clean_df[var1], clean_df[var2])
                    
                    # Ø³Ø¨ÙŠØ±Ù…Ø§Ù† (Spearman) - Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø±ØªØ¨ÙŠ
                    r_spearman, p_spearman = stats.spearmanr(clean_df[var1], clean_df[var2])
                    
                    # ÙƒÙŠÙ†Ø¯Ø§Ù„ (Kendall) - Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø±ØªØ¨ÙŠ
                    r_kendall, p_kendall = stats.kendalltau(clean_df[var1], clean_df[var2])
                    
                    results.append({
                        "Ø§Ù„Ù…ØªØºÙŠØ±_1": var1,
                        "Ø§Ù„Ù…ØªØºÙŠØ±_2": var2,
                        "Ø¨ÙŠØ±Ø³ÙˆÙ†_r": round(float(r_pearson), 3),
                        "Ø¨ÙŠØ±Ø³ÙˆÙ†_p": round(float(p_pearson), 4),
                        "Ø¨ÙŠØ±Ø³ÙˆÙ†_Ø¯Ø§Ù„": "Ù†Ø¹Ù… âœ…" if p_pearson < 0.05 else "Ù„Ø§ âŒ",
                        "Ø³Ø¨ÙŠØ±Ù…Ø§Ù†_rho": round(float(r_spearman), 3),
                        "Ø³Ø¨ÙŠØ±Ù…Ø§Ù†_p": round(float(p_spearman), 4),
                        "Ø³Ø¨ÙŠØ±Ù…Ø§Ù†_Ø¯Ø§Ù„": "Ù†Ø¹Ù… âœ…" if p_spearman < 0.05 else "Ù„Ø§ âŒ",
                        "ÙƒÙŠÙ†Ø¯Ø§Ù„_tau": round(float(r_kendall), 3),
                        "ÙƒÙŠÙ†Ø¯Ø§Ù„_p": round(float(p_kendall), 4),
                        "ÙƒÙŠÙ†Ø¯Ø§Ù„_Ø¯Ø§Ù„": "Ù†Ø¹Ù… âœ…" if p_kendall < 0.05 else "Ù„Ø§ âŒ",
                        "Ø§Ù„Ù‚ÙˆØ©": self._interpret_r(r_pearson),
                        "Ø§Ù„Ø§ØªØ¬Ø§Ù‡": "Ø·Ø±Ø¯ÙŠ â†—ï¸" if r_pearson > 0 else "Ø¹ÙƒØ³ÙŠ â†˜ï¸"
                    })
            
            return {"Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª": results}
        except Exception as e:
            return {"error": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·: {str(e)}"}
    
    def _interpret_r(self, r):
        """ØªÙØ³ÙŠØ± Ù‚ÙˆØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·"""
        abs_r = abs(r)
        if abs_r < 0.3:
            return "Ø¶Ø¹ÙŠÙ"
        elif abs_r < 0.5:
            return "Ù…ØªÙˆØ³Ø·"
        elif abs_r < 0.7:
            return "Ù‚ÙˆÙŠ"
        else:
            return "Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹"


class RegressionAnalyzer:
    """Ù…Ø­Ø±Ùƒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±"""
    
    def __init__(self, dataframe):
        self.df = dataframe
    
    def multiple_regression(self, dependent, independents):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù…ØªØ¹Ø¯Ø¯"""
        try:
            all_vars = [dependent] + independents
            clean_df = self.df[all_vars].dropna()
            
            X = clean_df[independents]
            y = clean_df[dependent]
            X = sm.add_constant(X)
            
            model = sm.OLS(y, X).fit()
            
            # Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
            coefficients = []
            for i, var in enumerate(['Ø§Ù„Ø«Ø§Ø¨Øª'] + independents):
                coefficients.append({
                    "Ø§Ù„Ù…ØªØºÙŠØ±": var,
                    "Ø§Ù„Ù…Ø¹Ø§Ù…Ù„": round(float(model.params[i]), 4),
                    "t": round(float(model.tvalues[i]), 3),
                    "p": round(float(model.pvalues[i]), 4),
                    "Ø¯Ø§Ù„": model.pvalues[i] < 0.05
                })
            
            return {
                "R2": round(float(model.rsquared), 4),
                "R2_Ù…Ø¹Ø¯Ù„": round(float(model.rsquared_adj), 4),
                "F": round(float(model.fvalue), 3),
                "p_F": round(float(model.f_pvalue), 4),
                "Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª": coefficients,
                "ØªÙØ³ÙŠØ±": f"Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠÙØ³Ø± {round(model.rsquared*100, 1)}% Ù…Ù† Ø§Ù„ØªØ¨Ø§ÙŠÙ†"
            }
        except Exception as e:
            return {"error": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±: {str(e)}"}


class ReportGenerator:
    """Ù…ÙˆÙ„Ø¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""
    
    def generate(self, results, analysis_type):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ù†ØµÙŠ Ù…Ù†Ø³Ù‚"""
        
        if analysis_type == 'descriptive':
            return self._format_descriptive(results)
        elif analysis_type == 'ttest':
            return self._format_ttest(results)
        elif analysis_type == 'anova':
            return self._format_anova(results)
        elif analysis_type == 'correlation':
            return self._format_correlation(results)
        elif analysis_type == 'regression':
            return self._format_regression(results)
        else:
            return str(results)
    
    def _format_descriptive(self, r):
        """ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØµÙÙŠ"""
        report = "ğŸ“Š *Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØµÙÙŠ*\n"
        report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        
        if r.get('Ù…ØªØºÙŠØ±Ø§Øª_Ø±Ù‚Ù…ÙŠØ©'):
            report += "*ğŸ”¢ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©:*\n\n"
            for v in r['Ù…ØªØºÙŠØ±Ø§Øª_Ø±Ù‚Ù…ÙŠØ©']:
                report += f"â–«ï¸ *{v['Ø§Ù„Ù…ØªØºÙŠØ±']}*\n"
                report += f"   â€¢ Ø§Ù„Ø¹Ø¯Ø¯: {v['Ø§Ù„Ø¹Ø¯Ø¯']}\n"
                report += f"   â€¢ Ø§Ù„Ù…ØªÙˆØ³Ø·: {v['Ø§Ù„Ù…ØªÙˆØ³Ø·']}\n"
                report += f"   â€¢ Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {v['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù_Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ']}\n"
                report += f"   â€¢ Ø§Ù„Ù…Ø¯Ù‰: {v['Ø£ØµØºØ±_Ù‚ÙŠÙ…Ø©']} - {v['Ø£ÙƒØ¨Ø±_Ù‚ÙŠÙ…Ø©']}\n\n"
        
        if r.get('Ù…ØªØºÙŠØ±Ø§Øª_ÙØ¦ÙˆÙŠØ©'):
            report += "*ğŸ“ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ÙØ¦ÙˆÙŠØ©:*\n\n"
            for v in r['Ù…ØªØºÙŠØ±Ø§Øª_ÙØ¦ÙˆÙŠØ©']:
                report += f"â–«ï¸ *{v['Ø§Ù„Ù…ØªØºÙŠØ±']}* ({v['Ø¹Ø¯Ø¯_Ø§Ù„ÙØ¦Ø§Øª']} ÙØ¦Ø©)\n"
                for cat in v['Ø§Ù„ØªÙˆØ²ÙŠØ¹'][:3]:
                    report += f"   â€¢ {cat['Ø§Ù„ÙØ¦Ø©']}: {cat['Ø§Ù„ØªÙƒØ±Ø§Ø±']} ({cat['Ø§Ù„Ù†Ø³Ø¨Ø©']}%)\n"
                report += "\n"
        
        return report
    
    def _format_ttest(self, r):
        """ØªÙ‚Ø±ÙŠØ± Ø§Ø®ØªØ¨Ø§Ø± T"""
        if 'error' in r:
            return f"âŒ Ø®Ø·Ø£: {r['error']}"
        
        report = "ğŸ“Š *Ù†ØªØ§Ø¦Ø¬ Ø§Ø®ØªØ¨Ø§Ø± T*\n"
        report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        
        report += f"*{r['Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©_1']['Ø§Ù„Ø§Ø³Ù…']}:*\n"
        report += f"â€¢ Ù† = {r['Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©_1']['Ø§Ù„Ø¹Ø¯Ø¯']}\n"
        report += f"â€¢ Ù… = {r['Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©_1']['Ø§Ù„Ù…ØªÙˆØ³Ø·']}\n"
        report += f"â€¢ Ø¹ = {r['Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©_1']['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù']}\n\n"
        
        report += f"*{r['Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©_2']['Ø§Ù„Ø§Ø³Ù…']}:*\n"
        report += f"â€¢ Ù† = {r['Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©_2']['Ø§Ù„Ø¹Ø¯Ø¯']}\n"
        report += f"â€¢ Ù… = {r['Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©_2']['Ø§Ù„Ù…ØªÙˆØ³Ø·']}\n"
        report += f"â€¢ Ø¹ = {r['Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©_2']['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù']}\n\n"
        
        report += "*Ø§Ù„Ù†ØªÙŠØ¬Ø©:*\n"
        report += f"â€¢ t = {r['t']}\n"
        report += f"â€¢ p = {r['p']}\n"
        report += f"â€¢ Cohen's d = {r['cohens_d']}\n\n"
        
        report += f"*âœ… Ø§Ù„ØªÙØ³ÙŠØ±:*\n{r['ØªÙØ³ÙŠØ±']}"
        
        return report
    
    def _format_anova(self, r):
        """ØªÙ‚Ø±ÙŠØ± ANOVA"""
        if 'error' in r:
            return f"âŒ Ø®Ø·Ø£: {r['error']}"
        
        report = "ğŸ“Š *Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¨Ø§ÙŠÙ† (ANOVA)*\n"
        report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        
        report += "*Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª:*\n"
        for g in r['Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª']:
            report += f"â€¢ {g['Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©']}: Ù†={g['Ø§Ù„Ø¹Ø¯Ø¯']}, Ù…={g['Ø§Ù„Ù…ØªÙˆØ³Ø·']}\n"
        
        report += f"\n*Ø§Ù„Ù†ØªÙŠØ¬Ø©:*\n"
        report += f"â€¢ F = {r['F']}\n"
        report += f"â€¢ p = {r['p']}\n\n"
        
        report += f"*âœ… Ø§Ù„ØªÙØ³ÙŠØ±:* {r['ØªÙØ³ÙŠØ±']}"
        
        return report
    
    def _format_correlation(self, r):
        """ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· - Ø¨ÙŠØ±Ø³ÙˆÙ†ØŒ Ø³Ø¨ÙŠØ±Ù…Ø§Ù†ØŒ ÙƒÙŠÙ†Ø¯Ø§Ù„"""
        if 'error' in r:
            return f"âŒ Ø®Ø·Ø£: {r['error']}"
        
        report = "ğŸ“Š *Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·*\n"
        report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        
        for c in r['Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª']:
            report += f"ğŸ”— *{c['Ø§Ù„Ù…ØªØºÙŠØ±_1']} â†”ï¸ {c['Ø§Ù„Ù…ØªØºÙŠØ±_2']}*\n"
            report += f"   {c['Ø§Ù„Ø§ØªØ¬Ø§Ù‡']} - {c['Ø§Ù„Ù‚ÙˆØ©']}\n\n"
            
            report += f"   ğŸ“Œ *Ø¨ÙŠØ±Ø³ÙˆÙ† (Pearson):*\n"
            report += f"      â€¢ r = {c['Ø¨ÙŠØ±Ø³ÙˆÙ†_r']}\n"
            report += f"      â€¢ p = {c['Ø¨ÙŠØ±Ø³ÙˆÙ†_p']}\n"
            report += f"      â€¢ Ø¯Ø§Ù„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Ù‹: {c['Ø¨ÙŠØ±Ø³ÙˆÙ†_Ø¯Ø§Ù„']}\n\n"
            
            report += f"   ğŸ“Œ *Ø³Ø¨ÙŠØ±Ù…Ø§Ù† (Spearman):*\n"
            report += f"      â€¢ rho = {c['Ø³Ø¨ÙŠØ±Ù…Ø§Ù†_rho']}\n"
            report += f"      â€¢ p = {c['Ø³Ø¨ÙŠØ±Ù…Ø§Ù†_p']}\n"
            report += f"      â€¢ Ø¯Ø§Ù„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Ù‹: {c['Ø³Ø¨ÙŠØ±Ù…Ø§Ù†_Ø¯Ø§Ù„']}\n\n"
            
            report += f"   ğŸ“Œ *ÙƒÙŠÙ†Ø¯Ø§Ù„ (Kendall):*\n"
            report += f"      â€¢ tau = {c['ÙƒÙŠÙ†Ø¯Ø§Ù„_tau']}\n"
            report += f"      â€¢ p = {c['ÙƒÙŠÙ†Ø¯Ø§Ù„_p']}\n"
            report += f"      â€¢ Ø¯Ø§Ù„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Ù‹: {c['ÙƒÙŠÙ†Ø¯Ø§Ù„_Ø¯Ø§Ù„']}\n"
            
            report += "\n" + "â”€"*30 + "\n\n"
        
        return report
    
    def _format_regression(self, r):
        """ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±"""
        if 'error' in r:
            return f"âŒ Ø®Ø·Ø£: {r['error']}"
        
        report = "ğŸ“Š *Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±*\n"
        report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        
        report += f"*Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:*\n"
        report += f"â€¢ RÂ² = {r['R2']} ({round(r['R2']*100, 1)}%)\n"
        report += f"â€¢ F = {r['F']} (p = {r['p_F']})\n\n"
        
        report += "*Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:*\n"
        for c in r['Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª']:
            sig = "âœ…" if c['Ø¯Ø§Ù„'] else "âŒ"
            report += f"{sig} {c['Ø§Ù„Ù…ØªØºÙŠØ±']}: Î²={c['Ø§Ù„Ù…Ø¹Ø§Ù…Ù„']} (p={c['p']})\n"
        
        report += f"\n*âœ… {r['ØªÙØ³ÙŠØ±']}*"
        
        return report


# ============= API ENDPOINTS =============

@app.route('/')
def home():
    """Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    return jsonify({
        "service": "Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ Ø§Ù„Ø¢Ù„ÙŠ - Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±",
        "version": "1.0",
        "status": "active",
        "endpoints": {
            "/health": "GET - ÙØ­Øµ Ø§Ù„ØµØ­Ø©",
            "/analyze": "POST - ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
        }
    })


@app.route('/health')
def health():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ø®Ø§Ø¯Ù…"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }), 200


@app.route('/analyze', methods=['POST'])
def analyze():
    """Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({"success": False, "error": "Ù„Ù… ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª"}), 400
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        if 'file_url' not in data or 'analysis_type' not in data:
            return jsonify({"success": False, "error": "file_url Ùˆ analysis_type Ù…Ø·Ù„ÙˆØ¨Ø§Ù†"}), 400
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
        file_handler = FileHandler()
        df = file_handler.load_file(data['file_url'])
        
        if df is None:
            return jsonify({"success": False, "error": "ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙˆØ§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª"}), 400
        
        # ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
        analysis_type = data['analysis_type'].lower()
        result = None
        
        if analysis_type == 'descriptive':
            analyzer = DescriptiveAnalyzer(df)
            result = analyzer.run_analysis()
        
        elif analysis_type == 'ttest':
            vars = data.get('variables', {})
            analyzer = InferentialAnalyzer(df)
            result = analyzer.ttest(vars.get('group_var'), vars.get('value_var'))
        
        elif analysis_type == 'anova':
            vars = data.get('variables', {})
            analyzer = InferentialAnalyzer(df)
            result = analyzer.anova(vars.get('dependent'), vars.get('independent'))
        
        elif analysis_type == 'correlation':
            vars = data.get('variables', {})
            analyzer = InferentialAnalyzer(df)
            result = analyzer.correlation(vars.get('list', []))
        
        elif analysis_type == 'regression':
            vars = data.get('variables', {})
            analyzer = RegressionAnalyzer(df)
            result = analyzer.multiple_regression(vars.get('dependent'), vars.get('independents', []))
        
        else:
            return jsonify({"success": False, "error": f"Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„ '{analysis_type}' ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…"}), 400
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        report_gen = ReportGenerator()
        report = report_gen.generate(result, analysis_type)
        
        return jsonify({
            "success": True,
            "analysis_type": analysis_type,
            "timestamp": datetime.now().isoformat(),
            "data": result,
            "report": report
        }), 200
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e),
            "traceback": traceback.format_exc()
        }), 500


if __name__ == '__main__':
    import os
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
